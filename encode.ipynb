{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(fan_in,fan_out,constant=1):\n",
    "    low=-constant*np.sqrt(6.0/(fan_in+fan_out))\n",
    "    high=constant*np.sqrt(6.0/(fan_in+fan_out))\n",
    "    return tf.random_uniform((fan_in,fan_out),minval=low,maxval=high,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveGaussianNoiseAutoencoder(object):\n",
    "    def __init__(self,n_input,n_hidden,transfer_function=tf.nn.softplus,\n",
    "                optimizer=tf.train.AdamOptimizer(),scale=0.1):\n",
    "        self.n_input=n_input\n",
    "        self.n_hidden=n_hidden\n",
    "        self.transfer=transfer_function\n",
    "        self.scale=tf.placeholder(tf.float32)\n",
    "        self.training_scale=scale\n",
    "        network_weights=self._initialize_weights()\n",
    "        self.weights=network_weights\n",
    "        self.x=tf.placeholder(tf.float32,[None,n_input])\n",
    "        self.hidden=self.transfer(tf.add(tf.matmul(\n",
    "                            self.x+scale*tf.random_normal((n_input,)),\n",
    "                                self.weights['w1']),self.weights['b1']))\n",
    "        self.reconstruction=tf.add(tf.matmul(self.hidden,self.weights['w2']),self.weights['b2'])\n",
    "        self.cost=0.5*tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction,self.x),2.0))\n",
    "        self.optimizer=optimizer.minimize(self.cost)\n",
    "        init=tf.global_variables_initializer()\n",
    "        self.sess=tf.Session()\n",
    "        self.sess.run(init)\n",
    "    def _initialize_weights(self):\n",
    "        all_weights=dict()\n",
    "        all_weights['w1']=tf.Variable(xavier_init(self.n_input,\n",
    "                                                self.n_hidden))\n",
    "        all_weights['b1']=tf.Variable(tf.zeros([self.n_hidden],\n",
    "                                              dtype=tf.float32))\n",
    "        all_weights['w2']=tf.Variable(tf.zeros([self.n_hidden,self.n_input],dtype=tf.float32))\n",
    "        all_weights['b2']=tf.Variable(tf.zeros([self.n_input],dtype=tf.float32))\n",
    "        return all_weights\n",
    "    \n",
    "    def partial_fit(self,X):\n",
    "        cost,opt=self.sess.run((self.cost,self.optimizer),\n",
    "                              feed_dict={self.x:X,self.scale:self.training_scale})\n",
    "        return cost\n",
    "    \n",
    "    def calc_total_cost(self,X):\n",
    "        return self.sess.run(self.cost,\n",
    "                             feed_dict={self.x:S,self.scale:self.training_scale})\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return self.sess.run(self.hidden,\n",
    "                            feed_dict={\n",
    "                                self.x:X,self.scale:self.training_scale\n",
    "                            })\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "    \n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_DATA',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(X_train,X_test):\n",
    "    preprocessor=prep.StandardScaler().fit(X_train)\n",
    "    X_train=preprocessor.transform(X_train)\n",
    "    X_test=preprocessor.transform(X_test)\n",
    "    return X_train,X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_block_from_data(data,batch_size):\n",
    "    start_index=np.random.randint(0,len(data)-batch_size)\n",
    "    return data[start_index:(start_index+batch_size)]\n",
    "X_train,X_test=standard_scale(mnist.train.images,mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=int(mnist.train.num_examples)\n",
    "training_epochs=200\n",
    "batch_size=128\n",
    "display_step=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder=AdditiveGaussianNoiseAutoencoder(n_input=784,\n",
    "                                            n_hidden=200,\n",
    "                                            transfer_function=tf.nn.softplus,\n",
    "                                            optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
    "                                            scale=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 cost= 7788.887432955\n",
      "epoch: 0002 cost= 8571.154782955\n",
      "epoch: 0003 cost= 7711.643556818\n",
      "epoch: 0004 cost= 8305.577836364\n",
      "epoch: 0005 cost= 7587.538670455\n",
      "epoch: 0006 cost= 7913.662339205\n",
      "epoch: 0007 cost= 7634.894287500\n",
      "epoch: 0008 cost= 7561.470842045\n",
      "epoch: 0009 cost= 7751.009475000\n",
      "epoch: 0010 cost= 8255.901509659\n",
      "epoch: 0011 cost= 7756.619589205\n",
      "epoch: 0012 cost= 7702.181657955\n",
      "epoch: 0013 cost= 7673.500871591\n",
      "epoch: 0014 cost= 7561.921728977\n",
      "epoch: 0015 cost= 7854.827261932\n",
      "epoch: 0016 cost= 7860.479686364\n",
      "epoch: 0017 cost= 8335.805289205\n",
      "epoch: 0018 cost= 8291.768567614\n",
      "epoch: 0019 cost= 8187.180946591\n",
      "epoch: 0020 cost= 6668.428705682\n",
      "epoch: 0021 cost= 7254.599762500\n",
      "epoch: 0022 cost= 7735.550426705\n",
      "epoch: 0023 cost= 7372.236004545\n",
      "epoch: 0024 cost= 7946.053638636\n",
      "epoch: 0025 cost= 7800.935125000\n",
      "epoch: 0026 cost= 7327.303769886\n",
      "epoch: 0027 cost= 7114.259218182\n",
      "epoch: 0028 cost= 7832.343958523\n",
      "epoch: 0029 cost= 7367.082698864\n",
      "epoch: 0030 cost= 7979.718875568\n",
      "epoch: 0031 cost= 7326.517540341\n",
      "epoch: 0032 cost= 7564.790338068\n",
      "epoch: 0033 cost= 7421.788782955\n",
      "epoch: 0034 cost= 7973.024416477\n",
      "epoch: 0035 cost= 7196.414186932\n",
      "epoch: 0036 cost= 7607.789774432\n",
      "epoch: 0037 cost= 7710.784376136\n",
      "epoch: 0038 cost= 7932.485926136\n",
      "epoch: 0039 cost= 7074.391145455\n",
      "epoch: 0040 cost= 7373.182095455\n",
      "epoch: 0041 cost= 6945.756452841\n",
      "epoch: 0042 cost= 7901.717913068\n",
      "epoch: 0043 cost= 8222.035565909\n",
      "epoch: 0044 cost= 7270.698610227\n",
      "epoch: 0045 cost= 7360.317788068\n",
      "epoch: 0046 cost= 7744.590125000\n",
      "epoch: 0047 cost= 7466.129065909\n",
      "epoch: 0048 cost= 7540.737289205\n",
      "epoch: 0049 cost= 7422.862167614\n",
      "epoch: 0050 cost= 7079.440067045\n",
      "epoch: 0051 cost= 7130.172732955\n",
      "epoch: 0052 cost= 7799.933295455\n",
      "epoch: 0053 cost= 6891.927096023\n",
      "epoch: 0054 cost= 7412.365798295\n",
      "epoch: 0055 cost= 7777.181982386\n",
      "epoch: 0056 cost= 7217.605763636\n",
      "epoch: 0057 cost= 7983.948938068\n",
      "epoch: 0058 cost= 7343.051471023\n",
      "epoch: 0059 cost= 7840.853310227\n",
      "epoch: 0060 cost= 7001.447943182\n",
      "epoch: 0061 cost= 7149.768943750\n",
      "epoch: 0062 cost= 7389.285788636\n",
      "epoch: 0063 cost= 7625.532605682\n",
      "epoch: 0064 cost= 7392.266271591\n",
      "epoch: 0065 cost= 7249.015448295\n",
      "epoch: 0066 cost= 7266.240290341\n",
      "epoch: 0067 cost= 7721.480724432\n",
      "epoch: 0068 cost= 6884.296865909\n",
      "epoch: 0069 cost= 7244.315810795\n",
      "epoch: 0070 cost= 6949.896377273\n",
      "epoch: 0071 cost= 7118.316711364\n",
      "epoch: 0072 cost= 7587.916039205\n",
      "epoch: 0073 cost= 7406.744971023\n",
      "epoch: 0074 cost= 7255.196375568\n",
      "epoch: 0075 cost= 7457.024369318\n",
      "epoch: 0076 cost= 7771.251594318\n",
      "epoch: 0077 cost= 7328.994781818\n",
      "epoch: 0078 cost= 8379.092999432\n",
      "epoch: 0079 cost= 7423.838064773\n",
      "epoch: 0080 cost= 8343.547237500\n",
      "epoch: 0081 cost= 7405.674490341\n",
      "epoch: 0082 cost= 7835.998944318\n",
      "epoch: 0083 cost= 7954.940382386\n",
      "epoch: 0084 cost= 7558.939361364\n",
      "epoch: 0085 cost= 7787.802264773\n",
      "epoch: 0086 cost= 7064.559421023\n",
      "epoch: 0087 cost= 8314.198459659\n",
      "epoch: 0088 cost= 7314.280930682\n",
      "epoch: 0089 cost= 7263.481325000\n",
      "epoch: 0090 cost= 7372.319991477\n",
      "epoch: 0091 cost= 7157.551979545\n",
      "epoch: 0092 cost= 7330.763467045\n",
      "epoch: 0093 cost= 7160.705410227\n",
      "epoch: 0094 cost= 7850.201553409\n",
      "epoch: 0095 cost= 7151.536432386\n",
      "epoch: 0096 cost= 7830.939373864\n",
      "epoch: 0097 cost= 7465.113585795\n",
      "epoch: 0098 cost= 7435.652546591\n",
      "epoch: 0099 cost= 7436.438366477\n",
      "epoch: 0100 cost= 7243.818844318\n",
      "epoch: 0101 cost= 7091.541359659\n",
      "epoch: 0102 cost= 7115.688643182\n",
      "epoch: 0103 cost= 7275.230909659\n",
      "epoch: 0104 cost= 7590.857630682\n",
      "epoch: 0105 cost= 7507.261650568\n",
      "epoch: 0106 cost= 6535.369186932\n",
      "epoch: 0107 cost= 6676.154127841\n",
      "epoch: 0108 cost= 7484.940760795\n",
      "epoch: 0109 cost= 6906.426404545\n",
      "epoch: 0110 cost= 7139.612536364\n",
      "epoch: 0111 cost= 8155.657138636\n",
      "epoch: 0112 cost= 7370.929063068\n",
      "epoch: 0113 cost= 7225.753928409\n",
      "epoch: 0114 cost= 7053.561003977\n",
      "epoch: 0115 cost= 7081.601185227\n",
      "epoch: 0116 cost= 7785.641894886\n",
      "epoch: 0117 cost= 7430.337936932\n",
      "epoch: 0118 cost= 7419.243194886\n",
      "epoch: 0119 cost= 7230.298347727\n",
      "epoch: 0120 cost= 6830.528459091\n",
      "epoch: 0121 cost= 7526.829978409\n",
      "epoch: 0122 cost= 7303.664239773\n",
      "epoch: 0123 cost= 6988.183515909\n",
      "epoch: 0124 cost= 7624.201152841\n",
      "epoch: 0125 cost= 7859.426965341\n",
      "epoch: 0126 cost= 7272.536416477\n",
      "epoch: 0127 cost= 7679.330943182\n",
      "epoch: 0128 cost= 7587.371289205\n",
      "epoch: 0129 cost= 6922.903643750\n",
      "epoch: 0130 cost= 7163.540044886\n",
      "epoch: 0131 cost= 7038.833423864\n",
      "epoch: 0132 cost= 6912.388269318\n",
      "epoch: 0133 cost= 7913.902061364\n",
      "epoch: 0134 cost= 7312.142073295\n",
      "epoch: 0135 cost= 7313.963229545\n",
      "epoch: 0136 cost= 7224.198898864\n",
      "epoch: 0137 cost= 7378.402483523\n",
      "epoch: 0138 cost= 7094.088255682\n",
      "epoch: 0139 cost= 7238.279281250\n",
      "epoch: 0140 cost= 7542.741780114\n",
      "epoch: 0141 cost= 7537.400532955\n",
      "epoch: 0142 cost= 7224.654884091\n",
      "epoch: 0143 cost= 7202.324851136\n",
      "epoch: 0144 cost= 7168.650101705\n",
      "epoch: 0145 cost= 7744.117360227\n",
      "epoch: 0146 cost= 7631.387540341\n",
      "epoch: 0147 cost= 6774.698251136\n",
      "epoch: 0148 cost= 7379.806413636\n",
      "epoch: 0149 cost= 7200.356492045\n",
      "epoch: 0150 cost= 7371.417665909\n",
      "epoch: 0151 cost= 7290.313330682\n",
      "epoch: 0152 cost= 7739.000547159\n",
      "epoch: 0153 cost= 7089.178246591\n",
      "epoch: 0154 cost= 7695.997636932\n",
      "epoch: 0155 cost= 7236.208165341\n",
      "epoch: 0156 cost= 7337.336488636\n",
      "epoch: 0157 cost= 7486.390646591\n",
      "epoch: 0158 cost= 7157.843572159\n",
      "epoch: 0159 cost= 7660.741157386\n",
      "epoch: 0160 cost= 7489.473909659\n",
      "epoch: 0161 cost= 7509.391153409\n",
      "epoch: 0162 cost= 7510.240368750\n",
      "epoch: 0163 cost= 7207.354144318\n",
      "epoch: 0164 cost= 7071.018892045\n",
      "epoch: 0165 cost= 7626.969200000\n",
      "epoch: 0166 cost= 7111.295031250\n",
      "epoch: 0167 cost= 7941.044002273\n",
      "epoch: 0168 cost= 7139.398873295\n",
      "epoch: 0169 cost= 6993.158785795\n",
      "epoch: 0170 cost= 7641.402415341\n",
      "epoch: 0171 cost= 7048.649744318\n",
      "epoch: 0172 cost= 6735.313642045\n",
      "epoch: 0173 cost= 8129.886693182\n",
      "epoch: 0174 cost= 7455.583085227\n",
      "epoch: 0175 cost= 7557.997351136\n",
      "epoch: 0176 cost= 6913.079802273\n",
      "epoch: 0177 cost= 7105.648189773\n",
      "epoch: 0178 cost= 7035.791876136\n",
      "epoch: 0179 cost= 7297.254452273\n",
      "epoch: 0180 cost= 6924.719432955\n",
      "epoch: 0181 cost= 6970.059054545\n",
      "epoch: 0182 cost= 7701.051165909\n",
      "epoch: 0183 cost= 7403.121194886\n",
      "epoch: 0184 cost= 8530.847523864\n",
      "epoch: 0185 cost= 7834.716635795\n",
      "epoch: 0186 cost= 7286.498921591\n",
      "epoch: 0187 cost= 7370.530152273\n",
      "epoch: 0188 cost= 7091.549894318\n",
      "epoch: 0189 cost= 7036.901789773\n",
      "epoch: 0190 cost= 7318.858502841\n",
      "epoch: 0191 cost= 7213.109234659\n",
      "epoch: 0192 cost= 7625.988484659\n",
      "epoch: 0193 cost= 7966.023471023\n",
      "epoch: 0194 cost= 7199.176859091\n",
      "epoch: 0195 cost= 7165.775289205\n",
      "epoch: 0196 cost= 7040.104695455\n",
      "epoch: 0197 cost= 7233.584749432\n",
      "epoch: 0198 cost= 7186.719413636\n",
      "epoch: 0199 cost= 7167.738540909\n",
      "epoch: 0200 cost= 7379.679652273\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=int(n_samples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs=get_random_block_from_data(X_train,batch_size)\n",
    "        cost=autoencoder.partial_fit(batch_xs)\n",
    "        avg_cost+=cost/n_samples*batch_size\n",
    "    if epoch%1==0:\n",
    "        print(\"epoch:\",'%04d'%(epoch+1),'cost=','{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
